{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daini10421/Mini-Project-55-Review-Analysis-Using-Transformers/blob/main/Mini_Project_55_Review_Analysis_Using_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting html stuff for the rest of the notebook\n",
        "from IPython.core.display import display, HTML, Javascript\n",
        "html_contents =\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "    <head>\n",
        "    <style>\n",
        "\n",
        "    .top_section{\n",
        "        background-color: #00AF87;\n",
        "        color: white;\n",
        "        font-family: Copperplate, Papyrus, fantasy;\n",
        "        font-weight: 800;\n",
        "        font-size: 35px;\n",
        "        padding: 20px 14px;\n",
        "        margin-bottom: 20px;\n",
        "    }\n",
        "\n",
        "\n",
        "    </style>\n",
        "    </head>\n",
        "\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "HTML(html_contents)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "cGb19biDvPiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><strong><h1> <div class=\"top_section\">In depth series 1: SENTIMENT ANALYSIS, why and how, EDA and solutions with Transformers</div></h1></strong></center>"
      ],
      "metadata": {
        "id": "mQaf21BsvPiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this study, I explained Sentiment Analysis in detail.\n",
        "\n",
        "I chose a sample dataset for Sentiment Analysis and embodied the subject I explained on a real example.\n",
        "\n",
        "Then I made a detailed analysis on the dataset and visualized it.\n",
        "\n",
        "After preprocessing the data, I tried to complete the Sentimet Analysis task with state-of-the-art models.\n",
        "\n",
        "I analyzed the results of this model and interpreted its outputs.\n",
        "\n",
        "I have indicated the sources I used while doing this study at the end of the notebook.\n",
        "Thank you to everyone who contributed to this field :)."
      ],
      "metadata": {
        "id": "SvhOGpNYvPiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1><div class=\"top_section\">Table of Contents </div></h1></center>\n",
        "\n",
        "1.  **[SENTIMENT ANALYSIS](#sentiment_analysis)**\n",
        "\n",
        "    - [Types of Sentiment Analysis](#types_of_sentiment_analysis)\n",
        "        - [Emotion Detection](#emotion_detection)\n",
        "        - [Multilingual Sentiment Analysis](#multilingual_sentiment_analysis)\n",
        "        - [Graded Sentiment Analysis](#graded_sentiment_analysis)\n",
        "        - [Aspect-based Sentiment Analysis](#aspect_base_sentiment_analysis)\n",
        "        - [Intent Analysis](#intent_analysis)\n",
        "        \n",
        "    - [Why Is Sentiment Analysis Important?](#why_is_sentiment_analysis_important)\n",
        "    \n",
        "    - [The overall benefits of sentiment analysis include](#the_overall_benefits_of_sentiment_analysis_include)\n",
        "        - [Sorting Data at Scale](#the_overall_benefits_of_sentiment_analysis_include)\n",
        "        - [Real-Time Analysis](#the_overall_benefits_of_sentiment_analysis_include)\n",
        "        - [Discovering New Marketing Strategies](#the_overall_benefits_of_sentiment_analysis_include)\n",
        "      \n",
        "    - [How Does Sentiment Analysis Work?](#how_does_sentiment_analysis_work)\n",
        "    \n",
        "    - [Sentiment analysis Approaches](#sentiment_analysis_Approaches)\n",
        "        - [Rule-based Approaches](#rule_based_approaches)\n",
        "        - [Automatic Approaches](#automatic_approaches)\n",
        "       \n",
        "2.  **[EDA](#eda)**\n",
        "       - [Information of the DATA](#information_of_the_data)\n",
        "       - [Information of the Problem](#information_of_the_problem)\n",
        "       - [Imports](#imports)\n",
        "       - [Helper Functions](#helper_functions)\n",
        "       - [Read Data](#read_data)\n",
        "       - [Visualizations](#visualizations)\n",
        "           - [Word Cloud](#word_cloud)\n",
        "           - [Target Count](#target_count)\n",
        "           - [Token Counts with simple tokenizer](#token_counts_with_simple_tokenizer)\n",
        "           - [Token Counts with BERT tokenizer](#token_counts_with_BERT_tokenizer)\n",
        "           - [Characters Count in the Data](#characters_count_in_the_data)\n",
        "           - [Reviews Lengths](#reviews_lengths)\n",
        "           - [Word Counts](#word_counts)\n",
        "           - [Most Common Words](#most_common_words)\n",
        "           - [Most Common ngrams](#most_common_ngrams)\n",
        "3.  **[MODELS](#models)**\n",
        "    - [A brief information about BERT](#brief_informartion_about_Bert)\n",
        "    - [A brief information about XLNET](#brief_informartion_about_XLNET)\n",
        "    - [A brief information about RoBERTa](#brief_informartion_about_RoBERTa)\n",
        "    - [Comparison of Transformer Models](#comparison_of_Transformer_Models)\n",
        "    - [Preprocess for BERT Train](#preprocess_for_BERT_Train)\n",
        "    - [Train and Validation Split](#Train_and_Validation_Split)\n",
        "    - [BertTokenizer and Encoding the Data](#BertTokenizer_and_Encoding_the1_Data)\n",
        "    - [Creating the Model](#Creating_the_Model)\n",
        "    - [Data Loaders](#Data_Loaders)\n",
        "    - [Optimizer & Scheduler](#Optimizer_Scheduler)\n",
        "    - [Performance Metrics](#Performance_Metrics)\n",
        "    - [Training Loop](#Training_Loop)\n",
        "    - [Test on validation set](#test)\n",
        "4. **[ERROR ANALYSIS](#error_analysis)**\n",
        "5. **[INFERENCE](#inference)**\n",
        "5. **[REFERENCES](#references)**\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "        \n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "Wm3MMjCCvPiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"sentiment_analysis\"></a>\n",
        "\n",
        "<center><h1><div class=\"top_section\">1. SENTIMENT ANALYSIS</div></h1></center>\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mek12/detailed_sentiment_analysis_with_transformers/main/images/sentimentanalysishotelgeneric-2048x803-1.jpg\">\n",
        "                \n",
        "                    source = https://d3caycb064h6u1.cloudfront.net/wp-content/uploads/2021/06/sentimentanalysishotelgeneric-2048x803-1.jpg\n"
      ],
      "metadata": {
        "id": "g5jFN9jvvPiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis (or opinion mining) is a natural language processing (NLP) technique used to determine whether data is positive, negative or neutral. Sentiment analysis is often performed on textual data to help businesses monitor brand and product sentiment in customer feedback, and understand customer needs.\n",
        "\n",
        "Sentiment analysis helps data analysts within large enterprises gauge public opinion, conduct nuanced market research, monitor brand and product reputation, and understand customer experiences. In addition,  companies often develop sentiment analysis systems for customer experience management, social media monitoring, or workforce analytics platform to about their own customers."
      ],
      "metadata": {
        "id": "vwCiDZn-vPiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"types_of_sentiment_analysis\"></a>\n",
        "<strong><h2>Types of Sentiment Analysis</h2></strong>\n",
        "\n",
        "![](https://raw.githubusercontent.com/mek12/detailed_sentiment_analysis_with_transformers/main/images/Sentiments-analysis_types.png)\n",
        "                \n",
        "                source = https://mobcoder.com/blog/sentimental-analysis-how-the-phenomenon-changing-the-dynamics-of-brand-monitoring/\n",
        "\n",
        "Sentiment analysis is aimed at determining the general emotional state of a text. One of these cases focuses on the polarity of a text (positive, negative, neutral) but it also goes beyond polarity to detect specific feelings and emotions (angry, happy, sad, etc), urgency (urgent, not urgent) and even intentions (interested v. not interested).\n",
        "\n",
        "Let's explain them in more detail"
      ],
      "metadata": {
        "id": "5c0FcOg8vPiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"emotion_detection\"></a>\n",
        "\n",
        "**Emotion Analysis**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mek12/detailed_sentiment_analysis_with_transformers/main/images/emotions_boy.jpg\" width=\"800\">\n",
        "\n",
        "            source = https://kids.frontiersin.org/articles/10.3389/frym.2018.00015\n",
        "\n",
        "The type of emotion analysis in which emotion types(happiness, frustration, anger, and sadness) are classified is called **emotion detection.**\n",
        "\n",
        "There are some difficulties with this classification. Users can express their feelings with many different words. They can use a word with a bad meaning for happiness. The most difficult examples of classification models here are; For example, the sentence \"I connect to customer service too late, it's killing me\" is a negative sentence, while the sentence \"you are killing me\" is positive."
      ],
      "metadata": {
        "id": "tYAiTBjLvPiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"multilingual_sentiment_analysis\"></a>\n",
        "\n",
        "\n",
        "**Multilingual Sentiment Analysis**\n",
        "\n",
        "\n",
        "It is the version of Sentiment Analysis systems that provides multi-language support. What is mentioned here is to do sentiment analysis in more than one language.\n",
        "\n",
        "I usually have two suggestions for this:\n",
        "\n",
        "My first suggestion is to detect the language of the text with the language classifier and run a sentimen analysis model suitable for this language. The second method is to develop a Multilingual language model and finetune this model and make the model work in many languages.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVIB9ZQEvPiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"#graded_sentiment_analysis\"></a>\n",
        "\n",
        "**Graded Sentiment Analysis**\n",
        "\n",
        "![](https://raw.githubusercontent.com/mek12/detailed_sentiment_analysis_with_transformers/main/images/gradient_Sentiment.png)\n",
        "            \n",
        "            source = https://i.pinimg.com/originals/5b/7d/62/5b7d62fb62b03b8142b402cb85644865.png\n",
        "\n",
        "If the precision of the mood is important, the categories can be further elaborated. A broader classification can be made, not just positive and negative:\n",
        "\n",
        "* Very positive\n",
        "* Positive\n",
        "* Neutral\n",
        "* Negative\n",
        "* Very negative\n",
        "\n",
        "\n",
        "This classification is often used in reviews and reviews where 5 stars are awarded.\n",
        "\n",
        "* Very Positive = 5 stars\n",
        "* Very Negative = 1 star\n"
      ],
      "metadata": {
        "id": "wae_vleCvPiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"aspect_base_sentiment_analysis\"></a>\n",
        "\n",
        "**Aspect-based Sentiment Analysis**\n",
        "\n",
        "![](https://raw.githubusercontent.com/mek12/detailed_sentiment_analysis_with_transformers/main/images/aspectbase.png)\n",
        "\n",
        "        source = https://www.surveysensum.com/wp-content/uploads/2020/02/SENTIMENT-09-1.png\n",
        "\n",
        "Generally, when analyzing the emotions of the texts, the focus is on determining whether the comment/opinion is positive or negative. But we do not focus on what is positive or negative in this text.\n",
        "\n",
        "To put it more clearly, in the expression \"I did not like the product at all, the size is too small\", the user is not satisfied with the product and complains about its dimensions. In a normal sentiment analysis, this sentence is classified as negative, but in **aspect-based sentiment analysis**, the \"the size is too small\" part is also focused on."
      ],
      "metadata": {
        "id": "a7_6nGz-vPiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"intent_analysis\"></a>\n",
        "\n",
        "**Intent Analysis**\n",
        "\n",
        "Intent analysis focuses on what the user wants to do. Understanding what the user wants to do will allow us to better guide him.\n",
        "\n",
        "For example, being able to understand that a customer browsing an e-commerce site has a shopping intention also allows us to offer him the right products.\n",
        "\n",
        "One of the most used areas is the smart assistant systems in the applications. It allows us to direct users to the right places within the application in line with their requests and we can offer a better application experience to the user.\n"
      ],
      "metadata": {
        "id": "fGbUCy_mvPiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"why_is_sentiment_analysis_important\"></a>\n",
        "\n",
        "\n",
        "**Why Is Sentiment Analysis Important?**\n",
        "\n",
        "![](https://brand24.com/blog/wp-content/uploads/2017/09/36896473_m-640x300.jpg)\n",
        "\n",
        "                    source = https://brand24.com/\n",
        "\n",
        "People now share their comments/emotions on social media, e-commerce sites and many other sites. A lot of data is created on these platforms.\n",
        "\n",
        "Often brands want to know what they are talking about. Brands/companies make great efforts to quickly identify their customers' expectations and provide them with the right service.It allows their customers to learn what makes them happy or disappointed so they can tailor products and services to their customers' needs.\n",
        "In addition, brands want to observe the impact of their advertisements on users.\n",
        "\n",
        "For these reasons, Sentiment analysis is becoming more important every day."
      ],
      "metadata": {
        "id": "fZm4lRjovPiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"the_overall_benefits_of_sentiment_analysis_include\"></a>\n",
        "\n",
        "**The overall benefits of sentiment analysis include:**\n",
        "\n",
        "**Sorting Data at Scale**\n",
        "\n",
        "Users make a lot of comments about brands, it is almost impossible to process them manually. Sentiment analysis enables businesses to automatically classify large amounts of raw data.\n",
        "\n",
        "\n",
        "**Real-Time Analysis**\n",
        "\n",
        "Companies can learn the wishes of their customers by analyzing the social media comments about you in real time. They can identify the angry customer and ensure his satisfaction.\n",
        "\n",
        "**Discovering New Marketing Strategies**\n",
        "\n",
        "With more data and information gathered through sentiment analysis, the organizations could develop an effective marketing strategy.\n",
        "\n",
        "The outcome from the strategies can be measured from the customers’ positive or negative key messages.\n",
        "\n",
        "By observing the customers’ conversations on their social media and detect the specific key messages related to your brand, specific marketing campaigns can be designed for the target consumers."
      ],
      "metadata": {
        "id": "lLylOm_qvPiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"how_does_sentiment_analysis_work\"></a>\n",
        "\n",
        "\n",
        "**How Does Sentiment Analysis Work?**\n",
        "\n",
        "<img src=\"https://monkeylearn.com/static/30607381159c995d7e967c1f0530e50f/95a1e/how-does-sentiment-analysis-work%402x.webp\" width=\"600\">\n",
        "                    \n",
        "                        source = https://monkeylearn.com/sentiment-analysis/\n",
        "\n",
        "\n",
        "Sentiment analysis works to automatically determine emotional tone thanks to natural language processing (NLP), rule-based methods, and machine learning algorithms.\n",
        "\n",
        "There are different ways we can do sentiment analysis, depending on how much data you need to analyze, how accurate your model needs to be, and how many resources you have.\n",
        "\n",
        "We will talk about some of them below.\n",
        "\n"
      ],
      "metadata": {
        "id": "9P1_mkc3vPiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"sentiment_analysis_Approaches\"></a>\n",
        "\n",
        "**Sentiment analysis algorithms fall into one of three buckets:**\n",
        "\n",
        "* <strong>Rule-based:</strong> these systems automatically perform sentiment analysis based on a set of manually crafted rules.\n",
        "* <strong>Automatic:</strong> systems rely on machine learning techniques to learn from data.\n"
      ],
      "metadata": {
        "id": "2TEW4CDcvPiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rule-based Approaches**\n",
        "\n",
        "Usually, a rule-based system tries to help determine the subjectivity of the sentence, the polarity, or the subject matter of an idea. The most used tool here is \"regex\".\n",
        "\n",
        "These rules usually include the following two NLP techniques:\n",
        "\n",
        "* Stemming, tokenization, part-of-speech tagging and parsing.\n",
        "* Lexicons (i.e. lists of words and expressions).\n",
        "\n",
        "\n",
        "The working mechanism of these systems is briefly as follows;\n",
        "\n",
        "1. Build a list of polarized words (e.g. bad-good, worst-best, ugly-beautiful etc). You can find them as open source\n",
        "\n",
        "2. The ratio of positive and positive words in a sentence\n",
        "\n",
        "Rule-based approaches are now obsolete, not used as much as they used to be. Rule-based approaches fail to detect ironies, not exactly how users are feeling. For this reason, automated approaches are gaining more importance now.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n7131-hrvPiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"automatic_approaches\"></a>\n",
        "\n",
        "**Automatic Approaches**\n",
        "\n",
        "These systems don’t rely on manually crafted rules, but on machine learning techniques, such as classification. Classification, which is used for sentiment analysis, is an automatic system that needs to be fed sample text before returning a category, e.g. positive, negative, or neutral.\n",
        "\n",
        "Here’s how a machine learning classifier can be implemented:\n",
        "\n"
      ],
      "metadata": {
        "id": "IFq54mdnvPiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification Algorithms**\n",
        "\n",
        "The classification step usually involves a statistical model like Naïve Bayes, Logistic Regression, Support Vector Machines, or Neural Networks:\n",
        "\n",
        "* <strong>Naïve Bayes:</strong> are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naïve) independence assumptions between the features (see Bayes classifier).\n",
        "* <strong>Linear Regression:</strong> is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables (also known as dependent and independent variables).\n",
        "* <strong>Support Vector Machines(SVM):</strong> is a supervised machine learning algorithm that can be used for classification or regression problems. However, it is mostly used in classification problems. Support Vector Machine is a boundary that best separates two classes (hyperplane/line)\n",
        "* <strong>Deep Learning:</strong> (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised."
      ],
      "metadata": {
        "id": "ksGHQQtXvPiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can explain the sentiment analysis in general like this. Now we have determined a data for how we will apply it next, and we will spread visualizations on that data and train models.**"
      ],
      "metadata": {
        "id": "GGDD5eMnvPiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"eda\"></a>\n",
        "<strong><center><h1><div class=\"top_section\">2. EDA</div></h1></center></strong>\n"
      ],
      "metadata": {
        "id": "QTzlJ80TvPiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"information_of_the_data\"></a>\n",
        "\n",
        "<strong><h1> Information of the Data </h1></strong>\n",
        "\n",
        "Hotels play a crucial role in traveling and with the increased access to information new pathways of selecting the best ones emerged.\n",
        "With this dataset, consisting of 20k reviews crawled from Tripadvisor, you can explore what makes a great hotel and maybe even use this model in your travels!\n",
        "\n",
        "<b>How to use</b>\n",
        "* Predict Review Rating\n",
        "* Topic Modeling on Reviews\n",
        "* Explore key aspects that make hotels good or bad"
      ],
      "metadata": {
        "id": "ls8e-lDgvPiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"information_of_the_problem\"></a>\n",
        "\n",
        "<strong><h1> Information of the Problem </h1></strong>\n",
        "\n",
        "Customer satisfaction is very important for the service industry. For this reason, it is necessary to determine the emotional state of the customer's thoughts. We need to classify the user's emotion in our hotel reviews data.\n",
        "\n"
      ],
      "metadata": {
        "id": "s7FsdWGyvPiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"imports\"></a>\n",
        "\n",
        "<strong><h1>Imports</h1></strong>"
      ],
      "metadata": {
        "id": "OdfkviDFvPiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from wordcloud import WordCloud\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "from plotly.offline import plot\n",
        "\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "B7wpnNdKvPiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "trusted": true,
        "id": "cxRBvQBUvPiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopWords_nltk = set(stopwords.words('english'))"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "dRBKgUDWvPiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"helper_functions\"></a>\n",
        "\n",
        "<strong><h1>Helper Functions</h1></strong>"
      ],
      "metadata": {
        "id": "4GzRAO5pvPiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from typing import Union, List\n",
        "\n",
        "class CleanText():\n",
        "    \"\"\" clearing text except digits () . , word character \"\"\"\n",
        "\n",
        "    def __init__(self, clean_pattern = r\"[^A-ZĞÜŞİÖÇIa-zğüı'şöç0-9.\\\"',()]\"):\n",
        "        self.clean_pattern =clean_pattern\n",
        "\n",
        "    def __call__(self, text: Union[str, list]) -> List[List[str]]:\n",
        "\n",
        "        if isinstance(text, str):\n",
        "            docs = [[text]]\n",
        "\n",
        "        if isinstance(text, list):\n",
        "            docs = text\n",
        "\n",
        "        text = [[re.sub(self.clean_pattern, \" \", sent) for sent in sents] for sents in docs]\n",
        "\n",
        "        return text\n",
        "\n",
        "def remove_emoji(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\" basic tokenize method with word character, non word character and digits \"\"\"\n",
        "    text = re.sub(r\" +\", \" \", str(text))\n",
        "    text = re.split(r\"(\\d+|[a-zA-ZğüşıöçĞÜŞİÖÇ]+|\\W)\", text)\n",
        "    text = list(filter(lambda x: x != '' and x != ' ', text))\n",
        "    sent_tokenized = ' '.join(text)\n",
        "    return sent_tokenized\n",
        "\n",
        "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "\n",
        "def remove_punct(text):\n",
        "    text = regex.sub(\" \", text)\n",
        "    return text\n",
        "\n",
        "clean = CleanText()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "3Y43me2ovPiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label encode\n",
        "def label_encode(x):\n",
        "    if x == 1 or x == 2:\n",
        "        return 0\n",
        "    if x == 3:\n",
        "        return 1\n",
        "    if x == 5 or x == 4:\n",
        "        return 2\n",
        "\n",
        "# label to name\n",
        "def label2name(x):\n",
        "    if x == 0:\n",
        "        return \"Negative\"\n",
        "    if x == 1:\n",
        "        return \"Neutral\"\n",
        "    if x == 2:\n",
        "        return \"Positive\"\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "achqu_B2vPiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"read_data\"></a>\n",
        "\n",
        "<strong><h1>Read Data</h1></strong>"
      ],
      "metadata": {
        "id": "WoQjsluXvPiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"../input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "hZPzy2PSvPiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show column names\n",
        "print(\"df.columns: \", df.columns)"
      ],
      "metadata": {
        "trusted": true,
        "id": "aw3RObASvPiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# head of df\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "KYQrn229vPiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count of ratings\n",
        "fig = px.histogram(df,\n",
        "             x = 'Rating',\n",
        "             title = 'Histogram of Review Rating',\n",
        "             template = 'ggplot2',\n",
        "             color = 'Rating',\n",
        "             color_discrete_sequence= px.colors.sequential.Blues_r,\n",
        "             opacity = 0.8,\n",
        "             height = 525,\n",
        "             width = 835,\n",
        "            )\n",
        "\n",
        "fig.update_yaxes(title='Count')\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "AEVGfCj3vPiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic info\n",
        "df.info()"
      ],
      "metadata": {
        "trusted": true,
        "id": "s7zvAznNvPiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode label and mapping label name\n",
        "df[\"label\"] = df[\"Rating\"].apply(lambda x: label_encode(x))\n",
        "df[\"label_name\"] = df[\"label\"].apply(lambda x: label2name(x))"
      ],
      "metadata": {
        "trusted": true,
        "id": "QGBq7sfTvPiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean text, lowercase and remove punk\n",
        "df[\"Review\"] = df[\"Review\"].apply(lambda x: remove_punct(clean(remove_emoji(x).lower())[0][0]))"
      ],
      "metadata": {
        "trusted": true,
        "id": "5t-sS1TmvPiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "u2dEOdaLvPiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"visualizations\"></a>\n",
        "\n",
        "\n",
        "<strong><h1>Visualizations</h1></strong>"
      ],
      "metadata": {
        "id": "-vCvEHoGvPiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"word_cloud\"></a>\n",
        "\n",
        "## Word Cloud\n",
        "\n",
        "Word clouds generators work by breaking the text down into component words and counting how frequently they appear in the body of text. We can quickly obtain preliminary information about the data. We can understand what a dataset we don't know is talking about."
      ],
      "metadata": {
        "id": "-FWZL-4evPiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_wordcloud(data, title = None):\n",
        "    wordcloud = WordCloud(\n",
        "        background_color='black',\n",
        "        max_words=200,\n",
        "        max_font_size=40,\n",
        "        scale=1,\n",
        "        random_state=1\n",
        ").generate(\" \".join(data))\n",
        "\n",
        "    fig = plt.figure(1, figsize=(15, 15))\n",
        "    plt.axis('off')\n",
        "    if title:\n",
        "        fig.suptitle(title, fontsize=20)\n",
        "        fig.subplots_adjust(top=2.3)\n",
        "\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "P5tFJ8movPiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_wordcloud(df[\"Review\"].values)"
      ],
      "metadata": {
        "trusted": true,
        "id": "DDol6dqbvPiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"target_count\"></a>\n",
        "\n",
        "## Target Count\n",
        "\n",
        "How many targets do we have? Learning this information will give us an idea about the model we will build. It will also provide guidance on our methods of analyzing data.\n"
      ],
      "metadata": {
        "id": "VYbxcFFavPiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"pie\"}, {\"type\": \"bar\"}]])\n",
        "colors = ['gold', 'mediumturquoise', 'lightgreen'] # darkorange\n",
        "fig.add_trace(go.Pie(labels=df.label_name.value_counts().index,\n",
        "                             values=df.label.value_counts().values), 1, 1)\n",
        "\n",
        "fig.update_traces(hoverinfo='label+percent', textfont_size=20,\n",
        "                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n",
        "\n",
        "fig.add_trace(go.Bar(x=df.label_name.value_counts().index, y=df.label.value_counts().values, marker_color = colors), 1,2)\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "loP_ypsWvPiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"token_counts_with_simple_tokenizer\"></a>\n",
        "\n",
        "## Token Counts with simple tokenizer\n",
        "\n",
        "Finding out the number of tokens available for each sample will give us information about the length of our data. The classification algorithm we will use for a long text will not be the same as the algorithm used for a short text."
      ],
      "metadata": {
        "id": "KX4_rgiivPiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize data\n",
        "df[\"tokenized_review\"] = df.Review.apply(lambda x: tokenize(x))\n",
        "# calculate token count for any sent\n",
        "df[\"sent_token_length\"] = df[\"tokenized_review\"].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "trusted": true,
        "id": "cOQDOZxwvPiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(df, x=\"sent_token_length\", nbins=20, color_discrete_sequence=px.colors.cmocean.algae, barmode='group', histnorm=\"percent\")\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "QdqtiTjKvPiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df.sent_token_length < 512).mean()"
      ],
      "metadata": {
        "trusted": true,
        "id": "_u7LaHEuvPiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"token_counts_with_BERT_tokenizer\"></a>\n",
        "\n",
        "## Token Counts with BERT tokenizer\n",
        "\n",
        "Since we will create a Transformers-based model, the value that BERT tokinezer will give us is very important. With the information here, the value of the `seq_len` parameter that we will use while encoding the data will be decided."
      ],
      "metadata": {
        "id": "s7M4_8xWvPiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
        "                                          do_lower_case=True)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "Ptb3602tvPiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data tokenize with bert tokenizer\n",
        "df[\"sent_bert_token_length\"] = df[\"Review\"].apply(lambda x: len(tokenizer(x, add_special_tokens=False)[\"input_ids\"]))"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "NWrmQwKAvPiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(df, x=\"sent_token_length\", nbins=20, color_discrete_sequence=px.colors.cmocean.algae, barmode='group', histnorm=\"percent\")\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Q2P6J2YSvPiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Less than 512 covers how many of the data\n",
        "(df.sent_bert_token_length < 512).mean()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "UXmHTg2EvPiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"characters_count_in_the_data\"></a>\n",
        "\n",
        "## Characters Count in the Data"
      ],
      "metadata": {
        "id": "QxoEwcN6vPiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's look at the frequency of the number of characters. It will give us information about the overall size of our data**"
      ],
      "metadata": {
        "id": "sEB3H--gvPiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# valvulate char count for each review\n",
        "df['char_count'] = df['Review'].apply(lambda x: len(str(x)))\n",
        "\n",
        "\n",
        "def plot_dist3(df, feature, title):\n",
        "    fig = plt.figure(constrained_layout=True, figsize=(18, 8))\n",
        "    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n",
        "    ax1 = fig.add_subplot(grid[0, :2])\n",
        "    ax1.set_title('Histogram')\n",
        "    sns.distplot(df.loc[:, feature],\n",
        "                 hist=True,\n",
        "                 kde=True,\n",
        "                 ax=ax1,\n",
        "                 )\n",
        "    ax1.set(ylabel='Frequency')\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(nbins=20))\n",
        "\n",
        "\n",
        "    plt.suptitle(f'{title}', fontsize=24)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "1j2SM9jxvPiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dist3(df, 'char_count',\n",
        "           'Characters Count in Data')"
      ],
      "metadata": {
        "trusted": true,
        "id": "l7gH9HMLvPiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"reviews_lengths\"></a>\n",
        "\n",
        "## Reviews Lengths\n",
        "\n",
        "\n",
        "When we look at the number of characters per comment, it can give us very striking information about the data. Here, when we look at the length of the comments made by people according to their feelings, negative comments are shorter than neutral and positive comments. We can come to the notion that people simply express negative things :)."
      ],
      "metadata": {
        "id": "Vj91F_EqvPiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new feature for the visualization.\n",
        "df['Character Count'] = df['Review'].apply(lambda x: len(str(x)))\n",
        "\n",
        "\n",
        "def plot_dist3(df, feature, title):\n",
        "    # Creating a customized chart. and giving in figsize and everything.\n",
        "    fig = plt.figure(constrained_layout=True, figsize=(24, 12))\n",
        "    # Creating a grid of 3 cols and 3 rows.\n",
        "    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n",
        "\n",
        "    # Customizing the histogram grid.\n",
        "    ax1 = fig.add_subplot(grid[0, :2])\n",
        "    # Set the title.\n",
        "    ax1.set_title('Histogram')\n",
        "    # plot the histogram.\n",
        "    sns.distplot(df.loc[:, feature],\n",
        "                 hist=True,\n",
        "                 kde=True,\n",
        "                 ax=ax1,\n",
        "                 color='#e74c3c')\n",
        "    ax1.set(ylabel='Frequency')\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(nbins=20))\n",
        "\n",
        "    # Customizing the ecdf_plot.\n",
        "    ax2 = fig.add_subplot(grid[1, :2])\n",
        "    # Set the title.\n",
        "    ax2.set_title('Empirical CDF')\n",
        "    # Plotting the ecdf_Plot.\n",
        "    sns.distplot(df.loc[:, feature],\n",
        "                 ax=ax2,\n",
        "                 kde_kws={'cumulative': True},\n",
        "                 hist_kws={'cumulative': True},\n",
        "                 color='#e74c3c')\n",
        "    ax2.xaxis.set_major_locator(MaxNLocator(nbins=20))\n",
        "    ax2.set(ylabel='Cumulative Probability')\n",
        "\n",
        "    plt.suptitle(f'{title}', fontsize=24)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "GWcUwGOtvPia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dist3(df[df['label'] == 0], 'Character Count',\n",
        "           'Characters Count \"Negative\" Rewiev')"
      ],
      "metadata": {
        "trusted": true,
        "id": "15pForpxvPia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dist3(df[df['label'] == 2], 'Character Count',\n",
        "           'Characters Per \"Positive\" Rewiev')"
      ],
      "metadata": {
        "trusted": true,
        "id": "CwUuDdN3vPia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dist3(df[df['label'] == 1], 'Character Count',\n",
        "           'Characters Per \"Neutral\" Rewiev')"
      ],
      "metadata": {
        "trusted": true,
        "id": "D16GMSs5vPia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"word_counts\"></a>\n",
        "\n",
        "## Word Counts\n",
        "\n",
        "We see that the situation in the number of characters and the situation in the number of words are the same. We have seen that people use less word count when expressing negative things."
      ],
      "metadata": {
        "id": "7hSoNFZ0vPia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_word_number_histogram(textno, textye, textz):\n",
        "\n",
        "    \"\"\"A function for comparing word counts\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=1, nrows=3, figsize=(18, 12), sharey=True)\n",
        "    sns.distplot(textno.str.split().map(lambda x: len(x)), ax=axes[0], color='#e74c3c')\n",
        "    sns.distplot(textye.str.split().map(lambda x: len(x)), ax=axes[1], color='#e74c3c')\n",
        "    sns.distplot(textz.str.split().map(lambda x: len(x)), ax=axes[2], color='#e74c3c')\n",
        "\n",
        "\n",
        "    axes[0].set_xlabel('Word Count')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    axes[0].set_title('negative')\n",
        "    axes[1].set_xlabel('Word Count')\n",
        "    axes[1].set_title('netrual')\n",
        "    axes[2].set_xlabel('Word Count')\n",
        "    axes[2].set_title('pozitive')\n",
        "\n",
        "    fig.suptitle('Words Per Review', fontsize=24, va='baseline')\n",
        "\n",
        "    fig.tight_layout()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "01z_nJwvvPia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_word_number_histogram(df[df['label'] == 0]['Review'],\n",
        "                           df[df['label'] == 1]['Review'],\n",
        "                           df[df['label'] == 2]['Review'],\n",
        "                          )"
      ],
      "metadata": {
        "trusted": true,
        "id": "c3nhNToUvPia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove punk\n",
        "df['tokenized_review'] = df['tokenized_review'].apply(lambda x: remove_punct(x))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "d2lLyrq3vPia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"most_common_words\"></a>\n",
        "## Most Common Words"
      ],
      "metadata": {
        "id": "67mJ3X6MvPib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['tokenized_review']\n",
        "new = texts.str.split()\n",
        "new = new.values.tolist()\n",
        "corpus = [word for i in new for word in i]\n",
        "counter = Counter(corpus)\n",
        "most = counter.most_common()\n",
        "x, y = [], []\n",
        "for word, count in most[:30]:\n",
        "    if word not in stopWords_nltk:\n",
        "        x.append(word)\n",
        "        y.append(count)\n",
        "\n",
        "fig = go.Figure(go.Bar(\n",
        "            x=y,\n",
        "            y=x,\n",
        "            orientation='h',  marker=dict(\n",
        "        color='rgba(50, 171, 96, 0.6)',\n",
        "        line=dict(\n",
        "            color='rgba(50, 171, 96, 1.0)',\n",
        "            width=1),\n",
        "    ),\n",
        "    name='Most common Word',))\n",
        "\n",
        "fig.update_layout( title={\n",
        "        'text': \"Most Common Words\",\n",
        "        'y':0.9,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'}, font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=18,\n",
        "        color=\"RebeccaPurple\"\n",
        "    ))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "FrjVmccOvPib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"most_common_ngrams\"></a>\n",
        "\n",
        "## Most Common ngrams"
      ],
      "metadata": {
        "id": "TyLeyJEsvPib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(rows=1, cols=3)\n",
        "title_ = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "for i in range(3):\n",
        "    texts = df[df[\"label\"] == i]['tokenized_review']\n",
        "\n",
        "    new = texts.str.split()\n",
        "    new = new.values.tolist()\n",
        "    corpus = [word for i in new for word in i]\n",
        "    counter = Counter(corpus)\n",
        "    most = counter.most_common()\n",
        "    x, y = [], []\n",
        "\n",
        "    for word, count in most[:30]:\n",
        "        if word not in stopWords_nltk:\n",
        "            x.append(word)\n",
        "            y.append(count)\n",
        "\n",
        "    fig.add_trace(go.Bar(\n",
        "                x=y,\n",
        "                y=x,\n",
        "                orientation='h', type=\"bar\",\n",
        "        name=title_[i], marker=dict(color=colors[i])), 1, i+1)\n",
        "\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=2000,\n",
        "    height=600,title=dict(\n",
        "        text='<b>Most Common ngrams per Classes</b>',\n",
        "        x=0.5,\n",
        "        y=0.95,\n",
        "        font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=24,\n",
        "        color=\"RebeccaPurple\"\n",
        "        )\n",
        "    ),)\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "v2E2uSS5vPib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_top_ngram(corpus, n=None):\n",
        "    #getting top ngrams\n",
        "    vec = CountVectorizer(ngram_range=(n, n),\n",
        "                          max_df=0.9,\n",
        "                          ).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx])\n",
        "                  for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
        "    return words_freq[:15]"
      ],
      "metadata": {
        "trusted": true,
        "id": "W2xIGAkcvPib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unigram\n",
        "fig = make_subplots(rows=1, cols=3)\n",
        "\n",
        "title_ = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "for i in range(3):\n",
        "    texts = df[df[\"label\"] == i]['tokenized_review']\n",
        "\n",
        "    new = texts.str.split()\n",
        "    new = new.values.tolist()\n",
        "    corpus = [word for i in new for word in i]\n",
        "    top_n_bigrams = _get_top_ngram(texts, 2)[:15]\n",
        "    x, y = map(list, zip(*top_n_bigrams))\n",
        "\n",
        "\n",
        "    fig.add_trace(go.Bar(\n",
        "                x=y,\n",
        "                y=x,\n",
        "                orientation='h', type=\"bar\",\n",
        "        name=title_[i], marker=dict(color=colors[i])), 1, i+1)\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=2000,\n",
        "    height=600,title=dict(\n",
        "        text='<b>Most Common unigrams per Classes</b>',\n",
        "        x=0.5,\n",
        "        y=0.95,\n",
        "        font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=24,\n",
        "        color=\"RebeccaPurple\"\n",
        "        )\n",
        "    ))\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "kdGnPA_xvPib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trigram\n",
        "\n",
        "fig = make_subplots(rows=1, cols=3)\n",
        "title_ = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "for i in range(3):\n",
        "    texts = df[df[\"label\"] == i]['tokenized_review']\n",
        "\n",
        "    new = texts.str.split()\n",
        "    new = new.values.tolist()\n",
        "    corpus = [word for i in new for word in i]\n",
        "\n",
        "    top_n_bigrams = _get_top_ngram(texts, 3)[:15]\n",
        "    x, y = map(list, zip(*top_n_bigrams))\n",
        "\n",
        "    fig.add_trace(go.Bar(\n",
        "                x=y,\n",
        "                y=x,\n",
        "                orientation='h', type=\"bar\",\n",
        "        name=title_[i], marker=dict(color=colors[i])), 1, i+1),\n",
        "\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=2000,\n",
        "    height=600,title=dict(\n",
        "        text='<b>Most Common trigrams per Classes</b>',\n",
        "        x=0.5,\n",
        "        y=0.95,\n",
        "        font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=24,\n",
        "        color=\"RebeccaPurple\"\n",
        "        )\n",
        "    ))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "M3stL04WvPic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We examined and visualized the data, now we can move on to the model building part.**"
      ],
      "metadata": {
        "id": "4ue_S3_xvPic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"models\"></a>\n",
        "<strong><center><h1><div class=\"top_section\">3. MODELS</div></h1></center></strong>\n"
      ],
      "metadata": {
        "id": "3LrNSs1ovPic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"brief_informartion_about_Bert\"></a>\n",
        "\n",
        "<strong><h2>A brief information about BERT</h2></strong>\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/mek12/detailed_sentiment_analysis_with_transformers/main/images/bert_arch.png)\n",
        "\n",
        "**BERT** makes use of Transformer, an attention mechanism that learns contextual relations between words (or sub-words) in a text. In its vanilla form, Transformer includes two separate mechanisms — an encoder that reads the text input and a decoder that produces a prediction for the task. Since BERT’s goal is to generate a language model, only the encoder mechanism is necessary.\n",
        "\n",
        "BERT is a bi-directional transformer for pre-training over a lot of unlabeled textual data to learn a language representation that can be used to fine-tune for specific machine learning tasks. While BERT outperformed the NLP state-of-the-art on several challenging tasks, its performance improvement could be attributed to the bidirectional transformer, novel pre-training tasks of Masked Language Model and Next Structure Prediction along with a lot of data and Google’s compute power.\n",
        "\n",
        "The detailed workings of Transformer are described in a paper by Google."
      ],
      "metadata": {
        "id": "D9UeJZvevPic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"brief_informartion_about_XLNET\"></a>\n",
        "\n",
        "<strong><h2>A brief information about XLNET</h2></strong>\n",
        "    \n",
        "![](https://raw.githubusercontent.com/mek12/detailed_sentiment_analysis_with_transformers/main/images/xlnet.png)\n",
        "\n",
        "**XLNet** is a large bidirectional transformer that uses improved training methodology, larger data and more computational power to achieve better than BERT prediction metrics on 20 language tasks.\n",
        "\n",
        "To improve the training, XLNet introduces permutation language modeling, where all tokens are predicted but in random order. This is in contrast to BERT’s masked language model where only the masked (15%) tokens are predicted. This is also in contrast to the traditional language models, where all tokens were predicted in sequential order instead of random order. This helps the model to learn bidirectional relationships and therefore better handles dependencies and relations between words. In addition, Transformer XL was used as the base architecture, which showed good performance even in the absence of permutation-based training.\n",
        "\n",
        "XLNet was trained with over 130 GB of textual data and 512 TPU chips running for 2.5 days, both of which ar e much larger than BERT.\n",
        "\n"
      ],
      "metadata": {
        "id": "EOOQfRUnvPic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"brief_informartion_about_RoBERTa\"></a>\n",
        "\n",
        "<strong><h2>A brief information about RoBERTa</h2></strong>\n",
        "    \n",
        "**RoBERTa**. Introduced at Facebook, Robustly optimized BERT approach RoBERTa, is a retraining of BERT with improved training methodology, 1000% more data and compute power.\n",
        "\n",
        "To improve the training procedure, RoBERTa removes the Next Sentence Prediction (NSP) task from BERT’s pre-training and introduces dynamic masking so that the masked token changes during the training epochs. Larger batch-training sizes were also found to be more useful in the training procedure.\n",
        "\n",
        "Importantly, RoBERTa uses 160 GB of text for pre-training, including 16GB of Books Corpus and English Wikipedia used in BERT. The additional data included CommonCrawl News dataset (63 million articles, 76 GB), Web text corpus (38 GB) and Stories from Common Crawl (31 GB). This coupled with whopping 1024 V100 Tesla GPU’s running for a day, led to pre-training of RoBERTa."
      ],
      "metadata": {
        "id": "2ODvPrr1vPid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<strong><h2>Comparison of Transformer Models</h2></strong>\n",
        "\n",
        "![](https://raw.githubusercontent.com/mek12/detailed_sentiment_analysis_with_transformers/main/images/transformers_model_compare.png)\n",
        "\n",
        "            source = https://towardsdatascience.com/bert-roberta-distilbert-xlnet-which-one-to-use-3d5ab82ba5f8\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JbpHUcj3vPid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this table, the models are compared under 5 headings, let's take them all one by one.**\n",
        "\n",
        "1. When we look at the sizes of the models, BERT, RoBERTa and XLNet have the same values, while the size of the DistillBERT is smaller.\n",
        "\n",
        "2. The biggest factor that determines Training Times is the size of the models and the data they have. As you can imagine, the time increases as the size increases :).\n",
        "\n",
        "3. When we look at the performance, BERT considers the model as the base model. RoBERTa offers 2-20% better performance than BERT. A similar performance applies to XLNet. XLNet performs 2-15% better than BERT model. DisltiBERT, despite its small size, is not equally poor in performance. It performs only 3% worse.\n",
        "\n",
        "4. When we look at its data, the model with the largest corpus is ROBERTa. It is followed by XLNET, then BERT and DistilBERT have the same data. One of the reasons for the higher performance of RoBERTa and XLNet is that the datasets are so high.\n",
        "\n",
        "\n",
        "5. As it is known, there are MLM and NSP tasks in the BERT model. The RoBERTa model is the trained version of the BERT model without the NSP task. DiltilBERT is a reduced number of parameters of BERT, it maintains 97% performance, but uses only half the number of parameters (paper). To enhance the training, XLNet offers permutation language modeling where all tokens are predicted but in random order.\n",
        "\n",
        "I recommend you to read the articles for more detailed information.\n",
        "\n"
      ],
      "metadata": {
        "id": "nzM32pVhvPid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"preprocess_for_BERT_Train\"></a>\n",
        "\n",
        "<strong><h1>Preprocess for BERT Train</h1></strong>"
      ],
      "metadata": {
        "id": "HC-RLysmvPid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "import json"
      ],
      "metadata": {
        "trusted": true,
        "id": "Lkmu2C36vPid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from transformers import BertForSequenceClassification"
      ],
      "metadata": {
        "trusted": true,
        "id": "74RInNkivPid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config():\n",
        "    seed_val = 17\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    epochs = 5\n",
        "    batch_size = 6\n",
        "    seq_length = 512\n",
        "    lr = 2e-5\n",
        "    eps = 1e-8\n",
        "    pretrained_model = 'bert-base-uncased'\n",
        "    test_size=0.15\n",
        "    random_state=42\n",
        "    add_special_tokens=True\n",
        "    return_attention_mask=True\n",
        "    pad_to_max_length=True\n",
        "    do_lower_case=False\n",
        "    return_tensors='pt'\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "trusted": true,
        "id": "uUrac9OCvPid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params will be saved after training\n",
        "params = {\"seed_val\": config.seed_val,\n",
        "    \"device\":str(config.device),\n",
        "    \"epochs\":config.epochs,\n",
        "    \"batch_size\":config.batch_size,\n",
        "    \"seq_length\":config.seq_length,\n",
        "    \"lr\":config.lr,\n",
        "    \"eps\":config.eps,\n",
        "    \"pretrained_model\": config.pretrained_model,\n",
        "    \"test_size\":config.test_size,\n",
        "    \"random_state\":config.random_state,\n",
        "    \"add_special_tokens\":config.add_special_tokens,\n",
        "    \"return_attention_mask\":config.return_attention_mask,\n",
        "    \"pad_to_max_length\":config.pad_to_max_length,\n",
        "    \"do_lower_case\":config.do_lower_case,\n",
        "    \"return_tensors\":config.return_tensors,\n",
        "         }"
      ],
      "metadata": {
        "trusted": true,
        "id": "1FF1NQRhvPid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed and device\n",
        "import random\n",
        "\n",
        "device = config.device\n",
        "\n",
        "random.seed(config.seed_val)\n",
        "np.random.seed(config.seed_val)\n",
        "torch.manual_seed(config.seed_val)\n",
        "torch.cuda.manual_seed_all(config.seed_val)"
      ],
      "metadata": {
        "trusted": true,
        "id": "93umA1sOvPid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "2svn4GlavPid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Train_and_Validation_Split\"></a>\n",
        "<strong><h2>Train and Validation Split</h2></strong>\n"
      ],
      "metadata": {
        "id": "u5rfgJ2pvPie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split train test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df_, val_df = train_test_split(df,\n",
        "                                    test_size=0.10,\n",
        "                                    random_state=config.random_state,\n",
        "                            stratify=df.label.values)"
      ],
      "metadata": {
        "trusted": true,
        "id": "lNAz3WGtvPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "r6SOcms6vPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(train_df_,\n",
        "                                    test_size=0.10,\n",
        "                                    random_state=42,\n",
        "                            stratify=train_df_.label.values)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Hyg-ReRMvPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count of unique label  control\n",
        "print(len(train_df['label'].unique()))\n",
        "print(train_df.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "DajNB-fXvPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count of unique label  control\n",
        "print(len(val_df['label'].unique()))\n",
        "print(val_df.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "drUcwyQdvPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_df['label'].unique()))\n",
        "print(test_df.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "YX1nUpi_vPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"BertTokenizer_and_Encoding_the1_Data\"></a>\n",
        "\n",
        "<strong><h2>BertTokenizer and Encoding the Data</h2></strong>"
      ],
      "metadata": {
        "id": "7ihIJKWivPie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(config.pretrained_model,\n",
        "                                          do_lower_case=config.do_lower_case)"
      ],
      "metadata": {
        "trusted": true,
        "id": "GZQ8_w_-vPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    train_df.Review.values,\n",
        "    add_special_tokens=config.add_special_tokens,\n",
        "    return_attention_mask=config.return_attention_mask,\n",
        "    pad_to_max_length=config.pad_to_max_length,\n",
        "    max_length=config.seq_length,\n",
        "    return_tensors=config.return_tensors\n",
        ")\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    val_df.Review.values,\n",
        "    add_special_tokens=config.add_special_tokens,\n",
        "    return_attention_mask=config.return_attention_mask,\n",
        "    pad_to_max_length=config.pad_to_max_length,\n",
        "    max_length=config.seq_length,\n",
        "    return_tensors=config.return_tensors\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "IwjzoyWKvPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(train_df.label.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(val_df.label.values)"
      ],
      "metadata": {
        "trusted": true,
        "id": "KJSWsEuivPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "metadata": {
        "trusted": true,
        "id": "tVZOe1YsvPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Creating_the_Model\"></a>\n",
        "\n",
        "<strong><h2>Creating the Model</h2></strong>"
      ],
      "metadata": {
        "id": "RLgzbItevPif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `bert-base-uncased` is a smaller pre-trained model.\n",
        "* Using `num_labels` to indicate the number of output labels."
      ],
      "metadata": {
        "id": "cpqvBMaNvPif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(config.pretrained_model,\n",
        "                                                      num_labels=3,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZtWmg4b2vPif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Data_Loaders\"></a>\n",
        "<strong><h2>Data Loaders</h2></strong>\n",
        "\n",
        "* `DataLoader` combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
        "* We use `RandomSampler` for training and `SequentialSampler` for validation.\n",
        "* Given the limited memory in my environment, I set `batch_size=64`."
      ],
      "metadata": {
        "id": "rXp6f2g9vPif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train,\n",
        "                              sampler=RandomSampler(dataset_train),\n",
        "                              batch_size=config.batch_size)\n",
        "\n",
        "dataloader_validation = DataLoader(dataset_val,\n",
        "                                   sampler=SequentialSampler(dataset_val),\n",
        "                                   batch_size=config.batch_size)"
      ],
      "metadata": {
        "trusted": true,
        "id": "jSSK54OOvPif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Optimizer_Scheduler\"></a>\n",
        "\n",
        "<strong><h2>Optimizer & Scheduler</h2></strong>"
      ],
      "metadata": {
        "id": "DxOFCMcIvPif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=config.lr,\n",
        "                  eps=config.eps)\n",
        "\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*config.epochs)"
      ],
      "metadata": {
        "trusted": true,
        "id": "x32szjE5vPif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Performance_Metrics\"></a>\n",
        "<strong><h2>Performance Metrics</h2></strong>\n",
        "\n",
        "We will use f1 score  as performance metrics."
      ],
      "metadata": {
        "id": "j5MLQHqkvPif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
        "\n",
        "def accuracy_per_class(preds, labels, label_dict):\n",
        "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "metadata": {
        "trusted": true,
        "id": "YKabABoivPif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Training_Loop\"></a>\n",
        "<strong><h2>Training Loop</h2></strong>"
      ],
      "metadata": {
        "id": "6Zh-SfQevPig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in dataloader_val:\n",
        "\n",
        "        batch = tuple(b.to(config.device) for b in batch)\n",
        "\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "    # calculate avareage val loss\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, predictions, true_vals"
      ],
      "metadata": {
        "trusted": true,
        "id": "FuUnZXJFvPig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config.device"
      ],
      "metadata": {
        "trusted": true,
        "id": "pvRyM2-rvPig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(config.device)\n",
        "\n",
        "for epoch in tqdm(range(1, config.epochs+1)):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    loss_train_total = 0\n",
        "    # allows you to see the progress of the training\n",
        "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        batch = tuple(b.to(config.device) for b in batch)\n",
        "\n",
        "\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), f'_BERT_epoch_{epoch}.model')\n",
        "\n",
        "    tqdm.write(f'\\nEpoch {epoch}')\n",
        "\n",
        "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "\n",
        "    tqdm.write(f'F1 Score (Weighted): {val_f1}');\n",
        "# save model params and other configs\n",
        "with Path('params.json').open(\"w\") as f:\n",
        "    json.dump(params, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "trusted": true,
        "id": "iAIQ3PQfvPig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"Test\"></a>\n",
        "<strong><h2>Test on validation set</h2></strong>"
      ],
      "metadata": {
        "id": "HmZ6RJbAvPig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(f'./_BERT_epoch_3.model', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "trusted": true,
        "id": "Aye0y0RAvPig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
        "print(classification_report(preds_flat, true_vals))"
      ],
      "metadata": {
        "trusted": true,
        "id": "l3sOZuXcvPig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"error_analysis\"></a>\n",
        "\n",
        "<strong><center><h1><div class=\"top_section\">4. ERROR ANALYSIS</div></h1></center></strong>\n"
      ],
      "metadata": {
        "id": "RWu3qc8DvPig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step by step predictions on dataframe\n",
        "# We do this to view predictions in the pandas dataframe and easily filter them and perform error analysis.\n",
        "\n",
        "pred_final = []\n",
        "\n",
        "for i, row in tqdm(val_df.iterrows(), total=val_df.shape[0]):\n",
        "    predictions = []\n",
        "\n",
        "    review = row[\"Review\"]\n",
        "    encoded_data_test_single = tokenizer.batch_encode_plus(\n",
        "    [review],\n",
        "    add_special_tokens=config.add_special_tokens,\n",
        "    return_attention_mask=config.return_attention_mask,\n",
        "    pad_to_max_length=config.pad_to_max_length,\n",
        "    max_length=config.seq_length,\n",
        "    return_tensors=config.return_tensors\n",
        "    )\n",
        "    input_ids_test = encoded_data_test_single['input_ids']\n",
        "    attention_masks_test = encoded_data_test_single['attention_mask']\n",
        "\n",
        "\n",
        "    inputs = {'input_ids':      input_ids_test.to(device),\n",
        "              'attention_mask':attention_masks_test.to(device),\n",
        "             }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.append(logits)\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    pred_final.append(np.argmax(predictions, axis=1).flatten()[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "GHZxqAzDvPig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add pred into val_df\n",
        "val_df[\"pred\"] = pred_final"
      ],
      "metadata": {
        "trusted": true,
        "id": "UxoRBGB-vPih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add control column for easier wrong and right predictions\n",
        "control = val_df.pred.values == val_df.label.values\n",
        "val_df[\"control\"] = control"
      ],
      "metadata": {
        "trusted": true,
        "id": "ed4NEx8FvPih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering false predictions\n",
        "val_df = val_df[val_df.control == False]"
      ],
      "metadata": {
        "trusted": true,
        "id": "PhiuOonbvPih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# buraları düzenle bbaaaabbaaaaa\n",
        "# label to intent mapping\n",
        "name2label = {\"Negative\":0,\n",
        "              \"Neutral\":1,\n",
        "             \"Positive\":2\n",
        "             }\n",
        "label2name = {v: k for k, v in name2label.items()}\n",
        "\n",
        "val_df[\"pred_name\"] = val_df.pred.apply(lambda x: label2name.get(x))"
      ],
      "metadata": {
        "trusted": true,
        "id": "vGo-TI6gvPik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# We create a confusion matrix to better observe the classes that the model confuses.\n",
        "pred_name_values = val_df.pred_name.values\n",
        "label_values = val_df.label_name.values\n",
        "confmat = confusion_matrix(label_values, pred_name_values, labels=list(name2label.keys()))"
      ],
      "metadata": {
        "trusted": true,
        "id": "7l6M_zs3vPil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confmat"
      ],
      "metadata": {
        "trusted": true,
        "id": "laZdzwBSvPil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_confusion_val = pd.crosstab(label_values, pred_name_values)\n",
        "df_confusion_val"
      ],
      "metadata": {
        "trusted": true,
        "id": "tVSnKnaEvPil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save confissuan matrix df\n",
        "df_confusion_val.to_csv(\"val_df_confusion.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "M2zH86pfvPil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"inference\"></a>\n",
        "\n",
        "<strong><center><h1><div class=\"top_section\">5. INFERENCE</div></h1></center></strong>"
      ],
      "metadata": {
        "id": "rCs4dDwXvPil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "elUfHCOsvPil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data_test = tokenizer.batch_encode_plus(\n",
        "    test_df.Review.values,\n",
        "    add_special_tokens=config.add_special_tokens,\n",
        "    return_attention_mask=config.return_attention_mask,\n",
        "    pad_to_max_length=config.pad_to_max_length,\n",
        "    max_length=config.seq_length,\n",
        "    return_tensors=config.return_tensors\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "WG6n0TKvvPil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_test = encoded_data_test['input_ids']\n",
        "attention_masks_test = encoded_data_test['attention_mask']\n",
        "labels_test = torch.tensor(test_df.label.values)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FBw96R11vPil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(config.pretrained_model,\n",
        "                                                      num_labels=3,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "model.to(config.device)\n",
        "\n",
        "model.load_state_dict(torch.load(f'./_BERT_epoch_3.model', map_location=torch.device('cpu')))\n",
        "\n",
        "_, predictions_test, true_vals_test = evaluate(dataloader_validation)\n",
        "# accuracy_per_class(predictions, true_vals, intent2label)"
      ],
      "metadata": {
        "trusted": true,
        "id": "OJBS65SJvPil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "preds_flat_test = np.argmax(predictions_test, axis=1).flatten()\n",
        "print(classification_report(preds_flat_test, true_vals_test))"
      ],
      "metadata": {
        "trusted": true,
        "id": "fXGcmdgXvPil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_final = []\n",
        "\n",
        "for i, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
        "    predictions = []\n",
        "\n",
        "    review = row[\"Review\"]\n",
        "    encoded_data_test_single = tokenizer.batch_encode_plus(\n",
        "    [review],\n",
        "    add_special_tokens=config.add_special_tokens,\n",
        "    return_attention_mask=config.return_attention_mask,\n",
        "    pad_to_max_length=config.pad_to_max_length,\n",
        "    max_length=config.seq_length,\n",
        "    return_tensors=config.return_tensors\n",
        "    )\n",
        "    input_ids_test = encoded_data_test_single['input_ids']\n",
        "    attention_masks_test = encoded_data_test_single['attention_mask']\n",
        "\n",
        "\n",
        "    inputs = {'input_ids':      input_ids_test.to(device),\n",
        "              'attention_mask':attention_masks_test.to(device),\n",
        "             }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.append(logits)\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    pred_final.append(np.argmax(predictions, axis=1).flatten()[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "6bqlhsm6vPim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add pred into test\n",
        "test_df[\"pred\"] = pred_final"
      ],
      "metadata": {
        "trusted": true,
        "id": "4TioPxw7vPim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add control column for easier wrong and right predictions\n",
        "control = test_df.pred.values == test_df.label.values\n",
        "test_df[\"control\"] = control"
      ],
      "metadata": {
        "trusted": true,
        "id": "DxIkZUnJvPim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering false predictions\n",
        "test_df = test_df[test_df.control == False]"
      ],
      "metadata": {
        "trusted": true,
        "id": "kgFXElMFvPim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[\"pred_name\"] = test_df.pred.apply(lambda x: label2name.get(x))"
      ],
      "metadata": {
        "trusted": true,
        "id": "dc1WrzCVvPim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# We create a confusion matrix to better observe the classes that the model confuses.\n",
        "pred_name_values = test_df.pred_name.values\n",
        "label_values = test_df.label_name.values\n",
        "confmat = confusion_matrix(label_values, pred_name_values, labels=list(name2label.keys()))"
      ],
      "metadata": {
        "trusted": true,
        "id": "KfsYMRPuvPim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confmat"
      ],
      "metadata": {
        "trusted": true,
        "id": "i8rWo7m2vPim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_confusion_test = pd.crosstab(label_values, pred_name_values)\n",
        "df_confusion_test"
      ],
      "metadata": {
        "trusted": true,
        "id": "1L0GwGXovPim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"references\"></a>\n",
        "\n",
        "<strong><center><h1><div class=\"top_section\">6. References</div></h1></center></strong>"
      ],
      "metadata": {
        "id": "9YDTaeNfvPim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. [Hugging Face](https://huggingface.co/)\n",
        "2. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
        "3. [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)\n",
        "4. [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237)\n",
        "5. [Coursera](https://www.coursera.org/projects/sentiment-analysis-bert)\n",
        "6. [Brand24](https://brand24.com/)\n",
        "7. [MonkeyLearn](https://monkeylearn.com/sentiment-analysis/)"
      ],
      "metadata": {
        "id": "CLJ_UjfTvPim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<strong><center><h1><div class=\"top_section\">If you like the notebook, Please don't forget to UPVOTE and comment  :) :)</div></h1></center></strong>"
      ],
      "metadata": {
        "id": "wX3W_vzovPim"
      }
    }
  ]
}